```{r}
#| label: setup
#| include: false
#| echo: false
#| eval: true

exData <- PM_data$new(data = "../Examples/src/ex.csv", loq = 1)
mod1 <- PM_model$new("../Examples/src/model.txt")
run2 <- PM_load(file = "../Examples/Runs/2/outputs/PMout.Rdata")
```

# Model validation 

Internal methods of validating include visual predictive check, prediction-corrected visual predictive check, numerical predictive check, and normalized prediction distribution errors (NPDE). These are all implemented in the `validate` method of the `PM_result` class. See `?PM_result$validate` for help.


For model validation - be sure to have executed the exercise on [NPAG run with covariates](NPAG_cov.qmd)). Type `?PM_valid` in the R console for help.

When executing the following code, choose `wt` as the covariate to bin. Accept all default bin sizes.

```{r}
run2$validate(limits = c(0, 3))
```


The default visual predictive check; ?plot.PM_valid for help
run2$valid$plot()

# or old S3
plot(run2$valid)


# Generate a prediction-corrected visual predictive check; type ?plot.PMvalid in the R console for help.
run2$valid$plot(type = "pcvpc")

# Create an npde plot
run2$valid$plot(type = "npde")

# Here is another way to generate a visual predicive check...
npc_2 <- run2$valid$simdata$plot(obs = run2$op, log = FALSE, binSize = 0.5)

# The jagged appearance of the plot when binSize=0 is because different subjects have
# different doses, covariates, and observation times, which are all combined in one simulation.
# Collapsing simulation times within 1 hour bins (binSize=1) smooths
# the plot, but can change the P-values in the numerical predictive check below.

npc_2
# ...and here is a numerical predictive check
# P-values are binomial test of proportion of observations less than
# the respective quantile
